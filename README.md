# ğŸš€ Databricks Lakehouse ETL Pipeline  
### Bronze â†’ Silver â†’ Gold | AWS S3 | PySpark | Delta Lake

A production-style **Data Engineering Lakehouse pipeline** built using  
**Databricks, PySpark, Delta Lake, and AWS S3**, implementing the modern  
**Medallion Architecture (Bronze, Silver, Gold)**.

This project demonstrates real-world enterprise data engineering patterns:
streaming ingestion, transformations, aggregations, and analytics-ready datasets.

---

## ğŸ§± Architecture Overview

### ğŸ¥‰ Bronze Layer (Raw Ingestion)
- Streaming ingestion from AWS S3 (CSV files)
- Spark Structured Streaming
- Raw Delta tables
- Checkpointing for fault tolerance

### ğŸ¥ˆ Silver Layer (Transformation)
- Data cleaning
- Type casting
- Deduplication
- Business transformations
- Clean Delta tables

### ğŸ¥‡ Gold Layer (Analytics)
- Aggregated datasets
- Customer analytics
- Business KPIs
- Reporting-ready tables

---

## ğŸ”„ Data Flow

AWS S3 (Raw CSV)  
â†’ Bronze Delta Table  
â†’ Silver Delta Table  
â†’ Gold Delta Table  
â†’ Analytics / BI / SQL

---

## ğŸ› ï¸ Tech Stack

- **Compute**: Databricks
- **Processing**: PySpark
- **Storage**: Delta Lake
- **Cloud**: AWS S3
- **Streaming**: Spark Structured Streaming
- **Architecture**: Lakehouse + Medallion Architecture

---

## ğŸ“‚ Repository Structure

```txt
notebooks/
  1_bronze_ingestion.py      # Raw data ingestion
  2_silver_transformation.py # Cleaning & transformations
  3_gold_aggregation.py      # Aggregations & analytics

utils/
  common_paths.py            # Centralized S3 path configs
